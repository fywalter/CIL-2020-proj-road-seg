{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os.path as osp\n",
    "import sys\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.modules.batchnorm import BatchNorm2d \n",
    "\n",
    "from config import config\n",
    "from dataloader import get_train_loader\n",
    "from network import CrfRnnNet\n",
    "from datasets import Cil\n",
    "\n",
    "from utils.init_func import init_weight, group_weight\n",
    "from engine.engine import Engine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_dict = model.psp.state_dict()\n",
    "# psp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr_dict = torch.load('./PSP_epoch-75.pth',map_location='cpu')['model']\n",
    "ptr_dict = {k: v for k, v in ptr_dict.items() if k in psp_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CrfRnnNet(2, n_iter=5)\n",
    "model.psp.load_state_dict(ptr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='mean',\n",
    "                                    ignore_index=-1)\n",
    "model = CrfRnnNet(config.num_classes, criterion=criterion,\n",
    "               pretrained_model=config.pretrained_model,\n",
    "               norm_layer=BatchNorm2d)\n",
    "base_lr = config.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "init_weight(model.psp.business_layer, nn.init.kaiming_normal_,\n",
    "            BatchNorm2d, config.bn_eps, config.bn_momentum,\n",
    "            mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "\n",
    "# group weight initialization on all layers\n",
    "params_list = []\n",
    "params_list = group_weight(params_list, model.psp.backbone,\n",
    "                           BatchNorm2d, base_lr)\n",
    "for module in model.psp.business_layer:\n",
    "    params_list = group_weight(params_list, module, BatchNorm2d,\n",
    "                               base_lr * 10)\n",
    "params_list.append(\n",
    "    dict(params=list(model.crfrnn.parameters()), weight_decay=.0, lr=base_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from crfasrnn.filters import SpatialFilter, BilateralFilter\n",
    "from crfasrnn.params import DenseCRFParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrfRnn(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of the CRF-RNN module described in the paper:\n",
    "\n",
    "    Conditional Random Fields as Recurrent Neural Networks,\n",
    "    S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang and P. Torr,\n",
    "    ICCV 2015 (https://arxiv.org/abs/1502.03240).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_labels, num_iterations=5, crf_init_params=None):\n",
    "        \"\"\"\n",
    "        Create a new instance of the CRF-RNN layer.\n",
    "\n",
    "        Args:\n",
    "            num_labels:         Number of semantic labels in the dataset\n",
    "            num_iterations:     Number of mean-field iterations to perform\n",
    "            crf_init_params:    CRF initialization parameters\n",
    "        \"\"\"\n",
    "        super(CrfRnn, self).__init__()\n",
    "        if crf_init_params is None:\n",
    "            crf_init_params = DenseCRFParams()\n",
    "\n",
    "        self.params = crf_init_params\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        # --------------------------------- Trainable Parameters -------------------------------------\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Spatial kernel weights\n",
    "        self.spatial_ker_weights = nn.Parameter(\n",
    "            crf_init_params.spatial_ker_weight\n",
    "            * torch.eye(num_labels, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        # Bilateral kernel weights\n",
    "        self.bilateral_ker_weights = nn.Parameter(\n",
    "            crf_init_params.bilateral_ker_weight\n",
    "            * torch.eye(num_labels, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        # Compatibility transform matrix\n",
    "        self.compatibility_matrix = nn.Parameter(\n",
    "            torch.eye(num_labels, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, logits):\n",
    "        \"\"\"\n",
    "        Perform CRF inference.\n",
    "\n",
    "        Args:\n",
    "            image:  Tensor of shape (3, h, w) containing the RGB image\n",
    "            logits: Tensor of shape (num_classes, h, w) containing the unary logits\n",
    "        Returns:\n",
    "            log-Q distributions (logits) after CRF inference\n",
    "        \"\"\"\n",
    "        \n",
    "        # if logits.shape[0] != 1:\n",
    "        #     raise ValueError(\"Only batch size 1 is currently supported!\")\n",
    "\n",
    "        # image = image[0]\n",
    "        # logits = logits[0]\n",
    "\n",
    "        \n",
    "\n",
    "        spatial_filter = SpatialFilter(image, gamma=self.params.gamma)\n",
    "        bilateral_filter = BilateralFilter(\n",
    "            image, alpha=self.params.alpha, beta=self.params.beta\n",
    "        )\n",
    "        _, h, w = image.shape\n",
    "        cur_logits = logits\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            # print(\"DANGER!\")    #debug\n",
    "            # Normalization\n",
    "            q_values = F.softmax(cur_logits, dim=0)\n",
    "\n",
    "            # Spatial filtering\n",
    "            spatial_out = torch.mm(\n",
    "                self.spatial_ker_weights,\n",
    "                spatial_filter.apply(q_values).view(self.num_labels, -1),\n",
    "            )\n",
    "\n",
    "            # Bilateral filtering\n",
    "            bilateral_out = torch.mm(\n",
    "                self.bilateral_ker_weights,\n",
    "                bilateral_filter.apply(q_values).view(self.num_labels, -1),\n",
    "            )\n",
    "\n",
    "            # Compatibility transform\n",
    "            msg_passing_out = (\n",
    "                spatial_out + bilateral_out\n",
    "            )  # Shape: (self.num_labels, -1)\n",
    "            msg_passing_out = torch.mm(self.compatibility_matrix, msg_passing_out).view(\n",
    "                self.num_labels, h, w\n",
    "            )\n",
    "\n",
    "            # Adding unary potentials\n",
    "            cur_logits = msg_passing_out + logits\n",
    "\n",
    "        return torch.unsqueeze(cur_logits, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crfrnn = CrfRnn(num_labels=2, num_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data = torch.randn(batch_size, 3, 512, 512)\n",
    "psp_fm = torch.randn(batch_size, 2, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "res = torch.zeros(1,2,512,512)\n",
    "for i in range(batch_size):\n",
    "    out = crfrnn(data[i], psp_fm[i])\n",
    "    res = torch.cat((res,out), dim=0)\n",
    "#     print(out.shape)\n",
    "res = res[1:]\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import CrfRnnNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CrfRnnNet(2,n_iter=1)\n",
    "ptr_model_pth = \"log/snapshot/epoch-last.pth\"\n",
    "ptr_dict = torch.load(ptr_model_pth, map_location='cpu')['model']\n",
    "model.load_state_dict(ptr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 9.9971e-01, -5.6362e-04],\n",
       "        [ 2.9005e-04,  1.0006e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.crfrnn.spatial_ker_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 9.9993e+00, -1.9934e-04],\n",
       "        [ 6.5538e-04,  1.0000e+01]], requires_grad=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.crfrnn.bilateral_ker_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9932, -0.0026],\n",
       "        [ 0.0068,  1.0026]], requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.crfrnn.compatibility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
